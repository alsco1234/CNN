# R(2+1)D

A Closer Look at Spatiotemporal Convolutions for Action Recognition
****Du Tran1,.. Facebook Research, Dartmouth College

<aside>
💡

</aside>

```
Paper : https://arxiv.org/pdf/1711.11248v3.pdf
review 1(kor) : https://junsk1016.github.io/deeplearning/R(2+1)D-%EB%A6%AC%EB%B7%B0/
review 2(eng) : https://medium.com/activity-recognition-in-untrimmed-videos/activity-recognition-in-untrimmed-videos-c88841094fe0
```

## 0. Abstract

비디오에서, 2D CNN은 개별 프레임에서 행동을 solid하게 인식했다. 그런데 residual learning(잔류 학습)에서는 2D CNN보다 3D CNN이 낫더라. 또 3D Conv filter을 공간과 시간으로 분리하면 accuracy 올라가더라.

따라서 새로운 spatiotemooral block(시공간 블록) R(2+1)D 으로 우수한 CNN 만들었다

---

## 1. I**ntroduction**

---

## 2. **Related Work**

---

## 3. **Convolutional residual blocks for video**

### **3.1. R2D : 2D convolutions over the entire clip**

### **3.2. f-R2D : 2D convolutions over frames**

### **3.3. R3D : 3D convolutions**

### **3.4. Mcx and rMCx : mixed 3D-3D convolutions**

### **3.5. R(2+1)D : (2+1)D convolutions**

---

## 4. **Experiments**

### **4.1. Experimental setup**

### **4.2. Comparison of spatiotemporal convolutions**

### **4.3. Revisiting practices for video-level prediction**

### **4.4. Action recognition with a 34-layer R(2+1)D net**

---

## 5. **Conclusions**

---

## 6. **Appendix**

[](https://www.notion.so/928b9ac1efbd4cd38ec0db3f18ab80c0)
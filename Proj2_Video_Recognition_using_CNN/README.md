요  약 
  동영상 데이터를 처리할 수 있도록 고안된 3D CNN의 등장과 발전에 따라 동영상 데이터의 분석과 이를 활용한 각종 예측 결과들도 빠르게 향상되어 가고 있다. 본 논문에서는 동영상 분석을 위한 R(2+1)D, I3D, S3D, X3D의 3D CNN 기반 기법들을 살펴보고 각각의 핵심 아이디어와 그 발전 양상을 일람한다. 또한 Kinetics-400 데이터셋을 활용하여 동영상 내 행동인식에 대한 벤치마크 실험을 수행하였고,정확도, 정밀도, 재현율, F1 score 및 실행 시간과 각 모델 별로 400개의 클래스에 대한 ROC 곡선의 평가 지표를 사용한 분석을 통해 소개한 각 3D CNN 기법들의 성능을 비교하고 성능상 차이가 발생하는 원인을 모델 구조를 토대로 가늠해본다. 동영상 분석에 있어 상황에 따라 유리한 3D CNN기법을 적절하게 선택하는 디지털 대전환의 방법을 제시한다.

  1. 서 론
  1989년 CNN(Convolutional Neural Network)[1]이 처음 제안된 이후로 2010년대 중반까지 사용된 대부분의 CNN 모델들은 가로, 세로로 배열된 2차원 이미지 데이터로부터 공간적 의존성(spatial dependency)을 추출하는 것에 집중해왔다. 이러한 모델들은 이미지 내의 사물을 구분하는 일에 효과적이었지만, 시간을 따라 연속적으로 변화하는 동영상 데이터에 대한 분류에는 여러 한계점을 드러냈다[2]. 이를 극복하기 위하여, 입력 데이터와 커널(Kernel)에 시간으로 해석될 수 있는 새로운 차원을 허용한 3차원 CNN(3D CNN)이 제안되었다[3].
 이미지 분류 위주로 활용되어 오던 CNN의 개념과 구조를 확장하여, 동영상 데이터의 효과적인 처리 목적으로 제안되었던 초기 방법으로서 C3D(Convolutional 3-Dimension)는 이미지 데이터에서 2차원 커널을 통해 이미지에 담긴 공간적 정보만 추출하는 일반적인 CNN 모델들과 달리, 시간(temporal)이라는 새로운 차원을 연산에 포함했다. 즉, C3D는 입력과 커널에 깊이(depth)라는 요소를 추가함으로써3차원 커널이 동영상에 담긴 시공간적(spatio-temporal) 의존성을 의사결정 과정에 사용할 수 있게 하였고, 이를 통해 보다 정확한 동영상의 처리가 가능하도록 고안된 모델이다. 하지만, 이렇게 추가된 차원을 갖는 CNN모델은 기존 2D CNN 모델의 이미지 처리에 비해 연산 및 시간적 요구량이 많다는 단점이 있었다. 이를 극복하기 위해 관련 연구계에서는 모델 내부 레이어(layer)의 구성을 변경하거나 시공간 외 다른 정보를 고려할 수 있도록 차원을 확장함으로써, 연산량을 줄이거나 동영상 분석에 더 적합한 특징맵(feature maps)을 추출하는 방법론들이 제시되었다.
   본 논문은 동영상 내 행동인식을 위해 C3D 등장 이후 3D CNN 구조의 확장 및 개선 방안으로서 제시되어 온 모델과 방법론 중 주요한 연구들을 요약적으로 살펴본다. 또한, 이들을 2017년 공개된 Kinetics-400[4] 데이터셋에 실제 적용하여 산출된 결과를 비교 분석하고자 한다. 이어지는 내용에서는 C3D 이후 큰 성능적 개선을 이룩한 I3D[5]를 포함하여 동영상 분석에 더 적합한 특징을 추출한 R(2+1)D[6], 문맥을 통해 입력 표현의 중점을 파악하는 S3D[7], 축을 확장하여 적은 연산량에도 높은 정확도를 갖는 X3D[8]의 총 네 가지 3D CNN 모델들을 일람한다.
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class C3D(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network as described in [1].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(C3D, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "            8개의 3D ConvNet 레이어 (3*3*3, stride=1*1*1)\n",
    "                각 특징 파악해 feature map 만듬\n",
    "            5개의 pooling layer(2*2*2, stride=2*2*2)....처음만 1*2*2\n",
    "                중요한 feature만 남김\n",
    "            2개의 fc 레이어\n",
    "                2차원을 1차원으로 평탄화\n",
    "                이전 레이어의 모든 노드가 연결되었기때문에 fully connected\n",
    "            softmax 출력 레이어\n",
    "        \"\"\"\n",
    "        \n",
    "        # 커널 사이즈 = d * k * k, 여기서 k=3으로 고정, d만변화\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1)) \n",
    "        # conv layer 1: 필터수 64, padding으로 크기 작아지지않게\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)) \n",
    "        # 첫번째 pooling에서는 1,2,2로 일단 시간 무시, polling과 stride는 같아야 모든 원소 처리. 이때 크기 감소함\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1)) # conv layer 2 : 필터수 128\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)) # max pooling으로 입력에서 출력 감소\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1)) # conv layer 3 : 필터수 256\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1)) # conv layer 2 : 필터수 256\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1)) # conv layer 2 : 필터수 256\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        # 논문대로 여기서 4096개 출력\n",
    "        self.fc8 = nn.Linear(4096, 487)\n",
    "        # 이미지 출력 위해 fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5) # overfitting 방지\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1) # 0~1의 확률로\n",
    "\n",
    "    # feedfoward network 쌓기\n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.pool1(h)\n",
    "\n",
    "        h = self.relu(self.conv2(h))\n",
    "        h = self.pool2(h)\n",
    "\n",
    "        h = self.relu(self.conv3a(h))\n",
    "        h = self.relu(self.conv3b(h))\n",
    "        h = self.pool3(h)\n",
    "\n",
    "        h = self.relu(self.conv4a(h))\n",
    "        h = self.relu(self.conv4b(h))\n",
    "        h = self.pool4(h)\n",
    "\n",
    "        h = self.relu(self.conv5a(h))\n",
    "        h = self.relu(self.conv5b(h))\n",
    "        h = self.pool5(h)\n",
    "\n",
    "        h = h.view(-1, 8192) # reshape, -1로 적절한 행 생성\n",
    "        h = self.relu(self.fc6(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.relu(self.fc7(h))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        logits = self.fc8(h)\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return probs\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
